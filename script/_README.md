A Novel Training Method of Generative Adversarial Network for Faithful Image Restoration. 논문의 실험.

> 1 ~ 6
one to many 논문에서 perceptual loss 대신 mse 를 이용하되, gan loss에 곱해지는 상수에 따른 효과 비교.

> 7 ~ 10
실험 결과가 뭔가 이상해서 좀 더 실험해 본 것. 알고보니 random crop 을 해줘야되는데 고정 crop 이 되어있었다. 실험 10에서 random crop시 다시 잘 됨을 확인. 
결국 baseline 부터 다시 뽑아야된다.

-------------------------------------------------------------------
> 11
qf10 에 대해 baseline 만드는 실험.

> 12
qf20 에 대해 baseline 만드는 실험.

> 14
qf05 에 대해 baseline 만드는 실험.

> 13
알고리즘 1

> 15
알고리즘 2

> 16
알고리즘 3
논문에 미리 언급한 내용보다 그냥 더 간단한 구조로 해봄.
어쩐지 긍정적 업데이트가 3epoch 정도 동안 10179 번 일어났다.
알고리즘 도중 gan_loss 에 대한 업데이트만 하는게 아니라 mse(baseline 학습) 도 같이 해주니까 많은 업데이트가 발생한다.

> 16_2
_exp016.py 와 달리 mse 로 학습시키는 것을 뺐보았다.
아마 긍정적 증가 횟수가 훨씬 줄 것이다.
# 결과
7 epoch 동안 17 번 긍정 없데이트
_exp016.py 에 비해 엄청 줄었다.

> 16_3
알고리즘 3 을 vgg 에 대해 적용해봄.
# 결과
학습이 잘 안된다.
대신 업데이트는 만번 이상 일어남
하지만 의미는 없는듯.

> 16_4
대신 exp016_3 과 다르게 상수를 곱해준다. 0.01 을 곱해보자.
# 결과
18 epoch 동안긍정적 update 가 3만번 이상 발생 하지만 결과 이미지는 학습이 불안정해보인다.

> 16_5

..

> 16_9
exp016 의 모든 실험은 잘못됐다..
VGE(vgg error) 함수의 input 을 순서를 거꾸로 했다..
그랬더니 결과가 안나온다.
이 부분에 대해 좀 더 실험해보고 싶지만 일단 넘긴다.
여하튼 순서를 잘 맞춰 넣어주자.

> 16_10
16_3 ~ 16_9 동안 vgg 에대해 잘못 실험 하면서 에서 얻은 교훈을 바탕으로 16_1 재대로 다시 실험.



> 17
one to many 논문에서 perceptual loss 대신 mse 를 이용하되, gan loss에 곱해지는 상수에 따른 효과 비교. 
0.1  
0.01  
0.001  
0.0001  
0.00001  
0.000001  
0  

> 특히 exp017_1 에서는 eval 할때 이미지의 크기에 따라 gan_loss * 0.1 에서 결과가 다르게 출력됨을 관찰하였다.

> 18
qf10 에 대해 최적의 vgg one to many 찾기


